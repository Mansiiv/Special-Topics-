{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Multimodel use cases"
      ],
      "metadata": {
        "id": "dqDkJn-bgJDx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip3 install --upgrade --user google-cloud-aiplatform\\\n",
        "                                        gitpython \\\n",
        "                                        magika"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "903nqAZjQApy",
        "outputId": "7d3bb053-2f51-4b05-c8e5-fd58f041541b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-aiplatform in /root/.local/lib/python3.10/site-packages (1.64.0)\n",
            "Requirement already satisfied: gitpython in /root/.local/lib/python3.10/site-packages (3.1.43)\n",
            "Requirement already satisfied: magika in /root/.local/lib/python3.10/site-packages (0.5.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.19.1)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (3.20.3)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (24.1)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.8.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (3.25.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.12.5)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.0.6)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.8.2)\n",
            "Requirement already satisfied: docstring-parser<1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (0.16)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /root/.local/lib/python3.10/site-packages (from gitpython) (4.0.11)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from magika) (8.1.7)\n",
            "Requirement already satisfied: numpy<2.0,>=1.26 in /usr/local/lib/python3.10/dist-packages (from magika) (1.26.4)\n",
            "Requirement already satisfied: onnxruntime<2.0.0,>=1.17.0 in /root/.local/lib/python3.10/site-packages (from magika) (1.19.0)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /root/.local/lib/python3.10/site-packages (from magika) (1.0.1)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from magika) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.2 in /usr/local/lib/python3.10/dist-packages (from magika) (4.66.5)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /root/.local/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython) (5.0.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.64.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.48.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.9)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.7.2)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.8.2)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.13.1)\n",
            "Requirement already satisfied: coloredlogs in /root/.local/lib/python3.10/site-packages (from onnxruntime<2.0.0,>=1.17.0->magika) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2.0.0,>=1.17.0->magika) (24.3.25)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2.0.0,>=1.17.0->magika) (1.13.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform) (4.12.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.5.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2024.7.4)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /root/.local/lib/python3.10/site-packages (from coloredlogs->onnxruntime<2.0.0,>=1.17.0->magika) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime<2.0.0,>=1.17.0->magika) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXMJq5isPo6X"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ID = \"inner-orb-434419-b6\"  # @param {type:\"string\"}\n",
        "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
        "\n",
        "import vertexai\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ],
      "metadata": {
        "id": "SLkrOljMPwz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from vertexai.generative_models import GenerativeModel, Image, Part\n"
      ],
      "metadata": {
        "id": "OnEHItAQPwxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "multimodal_model = GenerativeModel(\"gemini-1.5-pro-001\")\n",
        "\n",
        "multimodal_model_flash = GenerativeModel(\"gemini-1.5-flash-001\")"
      ],
      "metadata": {
        "id": "rrM256m8PwwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import http.client\n",
        "import typing\n",
        "import urllib.request\n",
        "import IPython.display\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "\n",
        "def get_image_bytes_from_url(image_url: str) -> bytes:\n",
        "    with urllib.request.urlopen(image_url) as response:\n",
        "        response = typing.cast(http.client.HTTPResponse, response)\n",
        "        image_bytes = response.read()\n",
        "    return image_bytes\n",
        "\n",
        "\n",
        "def load_image_from_url(image_url: str) -> Image:\n",
        "    image_bytes = get_image_bytes_from_url(image_url)\n",
        "    return Image.from_bytes(image_bytes)\n",
        "\n",
        "\n",
        "def display_content_as_video(content: str | Image | Part):\n",
        "    if not isinstance(content, Part):\n",
        "        return False\n",
        "    part = typing.cast(Part, content)\n",
        "    file_path = part.file_data.file_uri.removeprefix(\"gs://\")\n",
        "    video_url = f\"https://storage.googleapis.com/{file_path}\"\n",
        "    IPython.display.display(IPython.display.Video(video_url, width=350))"
      ],
      "metadata": {
        "id": "4_Zl0iiCPwt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Understanding the text\n"
      ],
      "metadata": {
        "id": "KuRAWQF-P6JR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What are some must-try local dishes in Mountain View, CA?\"\n",
        "prompt = \"\"\"\n",
        "Given these popular local dishes , recommend some restaurants\n",
        "or food spots in Mountain View where visitors can enjoy these authentic flavors.\n",
        "\"\"\"\n",
        "\n",
        "contents = [question, prompt]\n",
        "response = multimodal_model.generate_content(contents)\n",
        "display(IPython.display.Markdown(response.text))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 760
        },
        "id": "e2b5aoMhP4LI",
        "outputId": "4c3fc964-48c2-4a78-c900-ae0ab951f2e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Must-Try Local Dishes in Mountain View, CA & Where to Find Them:\n\nWhile Mountain View doesn't have its own distinct cuisine, it boasts incredible diversity and quality in its culinary scene.  Here are some \"must-try\" dishes reflecting that variety, along with specific restaurant recommendations:\n\n**1. World-Class Vietnamese:**  Mountain View is practically *famous* for Vietnamese food.\n\n* **Phá»Ÿ:**  Aromatic broth, rice noodles, meat, and fresh herbs.\n    * **Phá»Ÿ HÃ²a Noodle Soup:** Renowned for their rich, flavorful broth (multiple locations)\n    * **Pho Hoa Pasteur:**  Another local favorite, known for authentic Hanoi-style phá»Ÿ \n* **BÃºn Cháº£ HÃ  Ná»™i:** Vermicelli noodles, grilled pork, fresh herbs, dipping sauce. \n    * **Hanoi Bistro:**  Highly praised for their bÃºn cháº£ and other northern Vietnamese specialties\n* **BÃ¡nh MÃ¬:**  Crusty baguette sandwiches with various fillings (grilled meats, pate, pickled veggies).\n    * **Lee's Sandwiches:** A classic choice for quick, delicious bÃ¡nh mÃ¬ (multiple locations)\n    * **Xanh Vietnamese Restaurant:** Upscale option with unique bÃ¡nh mÃ¬ creations\n\n**2. Silicon Valley's Global Flavors:**  Mountain View's tech scene attracts cuisines from around the world.\n\n* **Ramen:**  Rich, flavorful Japanese noodle soup with various toppings.\n    * **Ramen Nagi:**  Customizable ramen with a wide selection of broths and toppings \n    * **Santouka Ramen:**  Known for their creamy, pork-based tonkotsu ramen\n* **Korean BBQ:**  Grill your own marinated meats at your table, served with banchan (small side dishes).\n    * **Gen Korean BBQ House:** Popular spot with all-you-can-eat options\n    * **Chungdam Korean Fusion Bistro:** Modern take on Korean classics, including BBQ\n* **Mediterranean:**  Fresh, flavorful dishes like falafel, hummus, shawarma.\n    * **Dishdash:** Popular spot for Middle Eastern and Mediterranean cuisine, try the mixed grill \n    * **Falafel Stop:**  As the name suggests, great spot for delicious falafel and shawarma\n\n**3. Californian Cuisine:**  Embrace the fresh, local ingredients.\n\n* **Farm-to-Table:**  Restaurants sourcing ingredients from nearby farms.\n    * **The Village Pub:** Michelin-starred restaurant with an emphasis on seasonal menus\n    * **Scratch:**  Casual eatery using locally sourced ingredients for their dishes\n* **Seafood:**  Being close to the Pacific, Mountain View offers fresh seafood options.\n    * **The Fish Market:**  Wide variety of fresh seafood, great for a special occasion\n    * **Cascal:**  Modern Mexican restaurant with a focus on seafood dishes\n\n\n**Beyond specific dishes:**\n\n* **Castro Street:**  The heart of Mountain View's dining scene with diverse options.\n* **Farmers' Markets:** Experience the local bounty, often with food vendors (Sundays on California St.)\n\nThis is just a starting point!  Don't hesitate to explore and discover your own Mountain View culinary favorites."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Document Summarization"
      ],
      "metadata": {
        "id": "ghhoZOIQgIbI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import vertexai\n",
        "\n",
        "from vertexai.generative_models import GenerativeModel, Part\n",
        "\n",
        "model = GenerativeModel(\"gemini-1.5-flash-001\")\n",
        "\n",
        "prompt = \"\"\"\n",
        "You are a very professional document summarization specialist.\n",
        "Please summarize the given document.\n",
        "\"\"\"\n",
        "\n",
        "pdf_file = Part.from_uri(\n",
        "    uri=\"gs://part-c-project/somatosensory.pdf\",\n",
        "    mime_type=\"application/pdf\",\n",
        ")\n",
        "contents = [pdf_file, prompt]\n",
        "\n",
        "response = model.generate_content(contents)\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-G6E2BSEvomC",
        "outputId": "5572f722-8bd6-4991-c8e0-a1e2d2cef160"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This document from Wikibooks discusses the anatomy of the somatosensory system which provides information about touch, temperature, pressure, pain, and position. The system is made up of cutaneous receptors located in the skin and receptors found in muscles and joints. The document outlines the different types of cutaneous receptors, describing their characteristics and functions. It also explains the structure and function of muscle spindles, the stretch receptors found in muscles. Finally, the document discusses the various types of joint receptors and their roles in providing information about the position and movement of joints.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image Understanding"
      ],
      "metadata": {
        "id": "s3FRH8EpmHvd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(contents=[...], stream = True)"
      ],
      "metadata": {
        "id": "3WKd0WNzyE_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import vertexai\n",
        "\n",
        "from vertexai.generative_models import GenerativeModel, Part\n",
        "\n",
        "# TODO(developer): Update project_id and location\n",
        "vertexai.init(project=PROJECT_ID, location=\"us-central1\")\n",
        "\n",
        "model = GenerativeModel(\"gemini-1.5-flash-001\")\n",
        "\n",
        "image_file = Part.from_uri(\n",
        "    \"gs://part-c-project/square face.png\", \"image/jpeg\"\n",
        ")\n",
        "\n",
        "# Query the model\n",
        "response = model.generate_content([image_file, \"what is this image?\"])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XxTEw9OwoDC",
        "outputId": "6778adaa-20e8-4c4d-dde7-257249ae5adc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is an image of a young woman with dark hair and brown eyes. She is wearing a white sweater and has her hair styled in a casual updo. The background is a light brown color. The photo is taken from the shoulders up, with the focus on the woman's face.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Video Understanding\n",
        "Generating a video description"
      ],
      "metadata": {
        "id": "ByuZGS4dyujI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Click here to watch video: https://drive.google.com/file/d/1B5YP3vd14xLALy0mMZG_NMh4htzZdyjP/view?usp=sharing"
      ],
      "metadata": {
        "id": "J8VD6Qenz4jg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "What is shown in this video?\n",
        "Which movie/series is this video from?\n",
        "What are the top 5 cartoons similar to this?\n",
        "\"\"\"\n",
        "video = Part.from_uri(\n",
        "    uri=\"gs://part-c-project/SampleVideo_1280x720_2mb.mp4\",\n",
        "    mime_type=\"video/mp4\",\n",
        ")\n",
        "contents = [prompt, video]\n",
        "\n",
        "responses = multimodal_model.generate_content(contents)\n",
        "\n",
        "display_content_as_video(video)\n",
        "display(IPython.display.Markdown(responses.text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "7cR9vtfNwoA6",
        "outputId": "44597ef7-878e-498d-a6a7-d2798cbc4c9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Video object>"
            ],
            "text/html": [
              "<video src=\"https://storage.googleapis.com/part-c-project/SampleVideo_1280x720_2mb.mp4\" controls  width=\"350\" >\n",
              "      Your browser does not support the <code>video</code> element.\n",
              "    </video>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The video shows a large, rotund rabbit waking up from a nap and taking in a deep breath of fresh air. It appears to be from a movie or series with 3D animation. \n\nUnfortunately, it is impossible to determine the exact movie or series from such a short clip.\n\nHowever, based on the art style, here are 5 cartoons that bear a resemblance and could be considered similar:\n\n1. **Over the Hedge:** This Dreamworks film features a similar animation style with anthropomorphic animals.\n2. **Open Season:**  Another Sony Pictures animation with talking animals and a bright, playful visual style.\n3. **Surf's Up:**  Although about penguins, this film shares a similar vibrancy and comedic tone.\n4. **Cloudy with a Chance of Meatballs:**  This film is visually comparable with its exaggerated characters and colorful world.\n5. **The Adventures of Tintin:**  While not exclusively focused on animals, Spielberg's Tintin film utilizes similar motion capture animation for its characters. \n\nWithout more context, pinpointing the exact source of the clip is difficult. \n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Audio Understanding"
      ],
      "metadata": {
        "id": "IGtrKyIg1SVT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  import vertexai\n",
        "  from vertexai.generative_models import GenerativeModel, Part\n",
        "\n",
        "  model = GenerativeModel(\"gemini-1.5-flash-001\")\n",
        "\n",
        "  prompt = \"\"\"\n",
        "  1. Please provide a comprehensive summary of this audio recording.\n",
        "  2. Focus on identifying the key points, main themes, and any critical information discussed.\n",
        "  3. Assess the emotional tone and sentiment throughout the audio.\n",
        "  4. Can you tell who is the speaker?\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "  audio_file_uri = \"gs://part-c-project/NzMxMDUyMTcyNzMxMTMz_t2_2foJnPt274.mp3\"\n",
        "  audio_file = Part.from_uri(audio_file_uri, mime_type=\"audio/mpeg\")\n",
        "\n",
        "  contents = [audio_file, prompt]\n",
        "\n",
        "  response = model.generate_content(contents)\n",
        "  print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCkrXGaG2gP9",
        "outputId": "6a619067-887d-4550-c79a-2980226e552e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This audio recording is a news segment that features an interview with Dr. Alice Krippen, a medical researcher who has made a breakthrough in cancer treatment. The interview starts by highlighting the significant medical advancements throughout history, comparing them to Dr. Krippen's work. \n",
            "\n",
            "Dr. Krippen explains that her research involves reprogramming a measles virus to work for the body rather than against it. She uses a car analogy to illustrate the process, comparing the virus to a speeding car driven by a \"bad man\" causing damage, and then replacing the \"bad man\" with a \"cop\" to change the picture. This demonstrates how they have engineered the virus to become beneficial. \n",
            "\n",
            "The interviewer then inquires about the number of patients treated and the results. Dr. Krippen reveals that they have conducted 10,009 clinical trials on humans, and all of them have resulted in cancer being cured. \n",
            "\n",
            "The tone of the interview is incredibly positive and optimistic, reflecting the groundbreaking nature of Dr. Krippen's discovery. The interviewer's excitement and disbelief are palpable, and the recording ends on a triumphant note. \n",
            "\n",
            "While the audio doesn't explicitly name the interviewer, it is evident that the interviewer is a journalist reporting on Dr. Krippen's research. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code Generation"
      ],
      "metadata": {
        "id": "Ed-2edHo6Bfa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74KV7wc86IJ4",
        "outputId": "fd9a8389-146d-4998-8dc6-3a1b3e92fae0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/365.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m \u001b[32m358.4/365.7 kB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m365.7/365.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/76.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”\u001b[0m \u001b[32m71.7/76.4 kB\u001b[0m \u001b[31m99.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to securely input API keys\n",
        "def get_api_key(api_name):\n",
        "    from google.colab import userdata\n",
        "    key = userdata.get(api_name)\n",
        "    if key is None:\n",
        "        raise ValueError(f\"{api_name} not found. Please set it in Colab.\")\n",
        "    return key\n",
        "\n",
        "# Set up OpenAI (GPT-4) API\n",
        "openai_client = OpenAI(api_key=get_api_key('OPENAI_API_KEY'))\n",
        "\n",
        "# Test GPT-4\n",
        "def test_gpt4():\n",
        "    response = openai_client.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[{\"role\": \"user\", \"content\": \"Say hello!\"}]\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "ztxhoCJV9Fru"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from openai import OpenAI\n",
        "import re\n",
        "\n",
        "# Assuming openai_client is already set up from the previous step\n",
        "client = OpenAI(api_key=get_api_key('OPENAI_API_KEY'))\n",
        "\n",
        "def generate_code_gpt4(prompt):\n",
        "    \"\"\"\n",
        "    Generate code based on a natural language prompt using GPT-4.\n",
        "    \"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that generates Python code based on natural language descriptions. Provide only the Python code without any additional explanation.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Generate Python code for the following task: {prompt}\"}\n",
        "        ]\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "def extract_python_code(text):\n",
        "    \"\"\"\n",
        "    Extract Python code from text, removing any markdown formatting.\n",
        "    \"\"\"\n",
        "    # Remove markdown code block syntax\n",
        "    code = re.sub(r'```python|```', '', text, flags=re.IGNORECASE)\n",
        "    return code.strip()\n",
        "\n",
        "# Example usage\n",
        "prompt = \"Create a function that takes a list of integers and returns a new list containing only the prime numbers.\"\n",
        "\n",
        "generated_code = generate_code_gpt4(prompt)\n",
        "print(\"Generated Code:\")\n",
        "print(generated_code)\n",
        "\n",
        "# Extract and execute the generated code\n",
        "extracted_code = extract_python_code(generated_code)\n",
        "print(\"\\nExtracted Code:\")\n",
        "print(extracted_code)\n",
        "\n",
        "exec(extracted_code)\n",
        "\n",
        "# Test the generated function\n",
        "test_list = [1, 2, 3, 4, 5, 11, 13, 17, 19, 23]\n",
        "result = filter_prime_numbers(test_list)  # This function name assumes GPT-4 used this name; adjust if different\n",
        "print(f\"\\nTesting the generated function with {test_list}\")\n",
        "print(f\"Result: {result}\")\n"
      ],
      "metadata": {
        "id": "-IUpIkBo6IH1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "861be8af-6760-4e9f-d563-e5cd03894985"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Code:\n",
            "```python\n",
            "def is_prime(n):\n",
            "    if n <= 1:\n",
            "        return False\n",
            "\n",
            "    for i in range(2, int(n**0.5) + 1):\n",
            "        if n % i == 0:\n",
            "            return False\n",
            "      \n",
            "    return True\n",
            "\n",
            "\n",
            "def filter_prime_numbers(lst):\n",
            "    return [num for num in lst if is_prime(num)]\n",
            "```\n",
            "\n",
            "Extracted Code:\n",
            "def is_prime(n):\n",
            "    if n <= 1:\n",
            "        return False\n",
            "\n",
            "    for i in range(2, int(n**0.5) + 1):\n",
            "        if n % i == 0:\n",
            "            return False\n",
            "      \n",
            "    return True\n",
            "\n",
            "\n",
            "def filter_prime_numbers(lst):\n",
            "    return [num for num in lst if is_prime(num)]\n",
            "\n",
            "Testing the generated function with [1, 2, 3, 4, 5, 11, 13, 17, 19, 23]\n",
            "Result: [2, 3, 5, 11, 13, 17, 19, 23]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Refactoring Code"
      ],
      "metadata": {
        "id": "UCagSb74-FLf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import re\n",
        "\n",
        "# Setup OpenAI client\n",
        "client = openai.OpenAI(api_key=get_api_key('OPENAI_API_KEY'))\n",
        "\n",
        "def generate_refactoring_suggestions(code, description):\n",
        "    \"\"\"\n",
        "    Generate refactoring suggestions based on a description of the desired improvements.\n",
        "    \"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that refactors Python code based on given descriptions. Provide only the Python code without any additional explanation.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Refactor the following Python code: {code}. {description}\"}\n",
        "        ]\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "def extract_python_code(text):\n",
        "    \"\"\"\n",
        "    Extract Python code from text, removing any markdown formatting.\n",
        "    \"\"\"\n",
        "    code = re.sub(r'```python|```', '', text, flags=re.IGNORECASE)\n",
        "    return code.strip()\n",
        "\n",
        "# Example existing code\n",
        "existing_code = \"\"\"\n",
        "def calculate_sum(lst):\n",
        "    result = 0\n",
        "    for num in lst:\n",
        "        result += num\n",
        "    return result\n",
        "\"\"\"\n",
        "\n",
        "# Desired refactoring: use list comprehension and improve performance if applicable\n",
        "description = \"Refactor this code to use list comprehension and enhance performance.\"\n",
        "\n",
        "# Generate refactoring suggestions\n",
        "refactoring_suggestions = generate_refactoring_suggestions(existing_code, description)\n",
        "print(\"Refactoring Suggestions:\")\n",
        "print(refactoring_suggestions)\n",
        "\n",
        "# Extract and possibly execute the refactored code\n",
        "refactored_code = extract_python_code(refactoring_suggestions)\n",
        "print(\"\\nRefactored Code:\")\n",
        "print(refactored_code)\n",
        "\n",
        "# Optionally, you can test the refactored code by executing it\n",
        "exec(refactored_code)\n",
        "test_list = [1, 2, 3, 4, 5]\n",
        "result = calculate_sum(test_list)\n",
        "print(f\"\\nTesting the refactored function with {test_list}\")\n",
        "print(f\"Result: {result}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAezS8Mg9GgA",
        "outputId": "2ea92645-ed72-48ba-c214-e9c123add99b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Refactoring Suggestions:\n",
            "def calculate_sum(lst):\n",
            "    return sum(num for num in lst)\n",
            "\n",
            "Refactored Code:\n",
            "def calculate_sum(lst):\n",
            "    return sum(num for num in lst)\n",
            "\n",
            "Testing the refactored function with [1, 2, 3, 4, 5]\n",
            "Result: 15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Content Generation"
      ],
      "metadata": {
        "id": "eeswBYzf-WvC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Setup OpenAI client\n",
        "client = openai.OpenAI(api_key=get_api_key('OPENAI_API_KEY'))\n",
        "\n",
        "def generate_content(prompt, content_type, max_tokens=150):\n",
        "    \"\"\"\n",
        "    Generate content based on a natural language prompt using GPT-4.\n",
        "    Parameters:\n",
        "        prompt (str): The content prompt describing what to write about.\n",
        "        content_type (str): Type of content, e.g., 'article', 'blog post', 'social media'.\n",
        "        max_tokens (int): Maximum number of tokens to generate.\n",
        "    \"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": f\"You are a creative assistant that generates {content_type} based on natural language prompts.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Generate a {content_type} about the following topic: {prompt}\"}\n",
        "        ],\n",
        "        max_tokens=max_tokens\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# Example usages\n",
        "article_prompt = \"the impact of climate change on global agriculture\"\n",
        "blog_post_prompt = \"top 5 tips for beginner yoga practitioners\"\n",
        "social_media_prompt = \"exciting announcement about our new product launch next week!\"\n",
        "\n",
        "# Generate different types of content\n",
        "article_content = generate_content(article_prompt, 'article', max_tokens=500)\n",
        "blog_content = generate_content(blog_post_prompt, 'blog post', max_tokens=300)\n",
        "social_media_content = generate_content(social_media_prompt, 'social media post', max_tokens=100)\n",
        "\n",
        "print(\"Generated Article Content:\")\n",
        "print(article_content)\n",
        "print(\"\\nGenerated Blog Post Content:\")\n",
        "print(blog_content)\n",
        "print(\"\\nGenerated Social Media Content:\")\n",
        "print(social_media_content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrjsAdhR-Dm2",
        "outputId": "efa37304-b33b-41a4-f20e-e17d5b0744a8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Article Content:\n",
            "Title: The Impact of Climate Change on Global Agriculture\n",
            "\n",
            "Introduction \n",
            "\n",
            "Climate change, a phenomenon marked by rising global temperatures, desertification, frequent occurrence of extreme weather events, and sea-level surges, is reshaping the overall schematic of our world. In this dynamic planetary rearrangement, no fieldâ€”literally and figurativelyâ€” remains immune, especially not the sector most dependent on Mother Nature: Agriculture. This article explores the multifaceted impact of climate change on global agriculture, altering everything from crop yields to distribution networks and posing significant challenges for future food security.\n",
            "\n",
            "Climate Change's Impact On Crop Cultivation\n",
            "\n",
            "Agriculture is an industry highly contingent on stable weather conditions and favorable climates. With climate change, this stability is under severe threat. Rising temperatures are often associated with increased evapotranspiration (the combination of evaporation and plant transpiration), which can reduce the availability of soil moisture vital for many crops resulting in lower yields. \n",
            "\n",
            "Furthermore, changes in the pattern of rainfall, with some regions experiencing excessive downpours and others bearing severe droughts under the influence of climate change, can also lead to a reduction in crop yields. For instance, water-intensive crops like rice and wheat are heavily affected by these climatic shifts that may result in poor crop health, reduced yield and stunted growth.\n",
            "\n",
            "Impact of Extreme Weather Events\n",
            "\n",
            "The rise in extreme weather events, such as hurricanes, storms, heatwaves, and floodsâ€” a direct effect of climate changeâ€” has added an additional layer of complexity for global agriculture. These extreme events can decimate entire fields of crops within hours, leave farmland unusable, and disrupt supply chains that transport agricultural produce to markets.\n",
            "\n",
            "Influence on Pests and Diseases\n",
            "\n",
            "The climate has a profound influence on the spread of pests and diseases affecting agricultural crops. Rising temperatures and changing rainfall patterns facilitate the spread of pests and diseases to newer regions, posing a significant risk to both crop yield and quality. For instance, warmer climates contribute to the increased prevalence and reproduction rate of crop pests such as locusts, aphids, and beetles.\n",
            "\n",
            "Sea-Level Rise and Salinity \n",
            "\n",
            "Another consequence of climate change affecting agriculture is sea-level rise, resulting in salinization of agricultural lands in coastal areas. Growing salty conditions make it difficult for most crops, leading to declining productivity and, in some cases, abandonment of agricultural lands.\n",
            "\n",
            "Impact on Livestock \n",
            "\n",
            "Climate change not only affects crops but also impacts the livestock sector. Heat stress can influence animals' metabolism,\n",
            "\n",
            "Generated Blog Post Content:\n",
            "Title: Embrace Serenity: Top 5 Tips for Beginner Yoga Practitioners \n",
            "\n",
            "Hello to all aspiring yogis and yoginis out there who are on the cusp of commencing their journey towards achieving harmony of mind, body, and spirit. Welcome to the world of asanas and pranayama, a path towards self-discovery, inner peace, and rejuvenation. \n",
            "\n",
            "Yoga, an ancient discipline, may seem overwhelming initially with its myriad poses, breathing techniques, and philosophical aspects. Yet, mastering yoga is a journey, not a destination. All it takes to get started is your commitment to learn and the willingness to embrace the ethos of yoga. To help you ease into this beautiful practice, here are the top five tips for beginner yoga practitioners.\n",
            "\n",
            "1. Start with a Yoga Class for Beginners: \n",
            "Even though there are numerous online tutorials and yoga apps, having a trained instructor guide you initially can be immensely beneficial. They will ensure that you understand the basics correctly, attain the right postures, and perform exercises safely, which can prevent any potential injuries. Hence, consider joining a beginner's yoga class in your local area or opt for virtual classes if you prefer learning from the comfort of your home.\n",
            "\n",
            "2. Grasp Basic Yoga Etiquettes: \n",
            "A yoga class is not your ordinary gym session. It warrants a serene and respectful atmosphere. Avoid eating at least two hours before a yoga session. Wear comfortable clothing that allows ease of movement, and try to arrive a\n",
            "\n",
            "Generated Social Media Content:\n",
            "ğŸ“£Get ready, folks! We are excited to announce that our NEW product will be launched next week! ğŸ‰ A game-changer that promises to elevate your experience and redefine industry standards. Teasers? Stay tuned, we've got so much in stock for you. Trust us, the wait will surely be worth it. Mark your calendars! ğŸ—“ï¸ #NewProduct #ProductLaunch #ComingSoon #ExcitingNews\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creative Arts using OpenAI GPT-4"
      ],
      "metadata": {
        "id": "QqUut8xH-z0C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Setup OpenAI client\n",
        "client = openai.OpenAI(api_key=get_api_key('OPENAI_API_KEY'))\n",
        "\n",
        "def generate_creative_content(prompt, content_type, max_tokens=200):\n",
        "    \"\"\"\n",
        "    Generate creative content based on a natural language prompt using GPT-4.\n",
        "    Parameters:\n",
        "        prompt (str): The content prompt describing the creative task.\n",
        "        content_type (str): Type of creative content, e.g., 'story', 'script', 'music composition'.\n",
        "        max_tokens (int): Maximum number of tokens to generate.\n",
        "    \"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": f\"You are an artistic assistant that generates {content_type} based on natural language prompts.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Generate a {content_type} based on the following idea: {prompt}\"}\n",
        "        ],\n",
        "        max_tokens=max_tokens\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# Example usages\n",
        "story_prompt = \"a young wizard discovering their powers in a modern city\"\n",
        "script_prompt = \"a dialogue between two old friends who accidentally meet after 20 years at an airport\"\n",
        "music_composition_prompt = \"compose a short piece in the style of Baroque music for a piano\"\n",
        "\n",
        "# Generate different types of creative content\n",
        "story_content = generate_creative_content(story_prompt, 'story', max_tokens=500)\n",
        "script_content = generate_creative_content(script_prompt, 'script', max_tokens=500)\n",
        "music_composition_content = generate_creative_content(music_composition_prompt, 'music composition', max_tokens=300)\n",
        "\n",
        "print(\"Generated Story Content:\")\n",
        "print(story_content)\n",
        "print(\"\\nGenerated Script Content:\")\n",
        "print(script_content)\n",
        "print(\"\\nGenerated Music Composition Content:\")\n",
        "print(music_composition_content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITo_j9nI-aZo",
        "outputId": "ed255dfb-19e5-4211-ecad-6833ed3ac605"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Story Content:\n",
            "Title: The Awakening of Urban Sorcery\n",
            "\n",
            "In the bustling modern city of New York, where skyscrapers kissed the sky amidst the bustling crowd, chaotic honks, and flashing neon lights, lived an unassuming teenager named Max. Everyone knew Max as an introverted, yet brilliant gamer and technology enthusiast. However, one unexpected day, Max's ordinary life would take a spellbinding turn. He would discover he was not as ordinary as he perceived himself to be; he was, in fact, a wizard.\n",
            "\n",
            "Maxâ€™s revelation came in a rather inadvertent manner. One day, while he was in a heated gaming competition, frustration rushed over him as he was on the verge of losing. In his frustration, he unconsciously wished the power would cut. To his absolute surprise and horror, not a moment later, there was a sudden, unexplained blackout across the entire block. With his heart pounding and mind swirling with questions, he started to suspect that the blackout was not a coincidence at all.\n",
            "\n",
            "Over the next few days, other inexplicable incidents occurred. He noticed his game console repairing itself overnight, sparks flying from his fingers whilst attempting to fix a fried circuit board, and ended up frying his computer when he was overwhelmed with schoolwork. Max began to fear these perplexing changes, and his suspicion that he influenced them grew stronger. He didn't just break or fry electronics; it seemed like he could manipulate their energy.\n",
            "\n",
            "Amidst the consternation, Max remembered his late grandmother's stories about their family's magical lineage, which he had dismissed as fairy tales meant to lull him to sleep. Now, he cautiously began to wonder if he might've dismissed these tales too hastily.\n",
            "\n",
            "Resolving to uncover the truth, Max dug out his grandmother's old journals. Indeed, they were filled with countless notes and diagrams of spells, magical theory and, to his astoundment, information about magical bloodlines. Max was a wizard, an electric wizard to be precise, descendant of a lineage that had fine command over electric energy and could manipulate it. His powers had laid dormant and now, as he bridged into adulthood, they were awakening, growing more potent by the day.\n",
            "\n",
            "Understanding his newly discovered power brought Max a sense of relief, but also came with its set of challenges. He was a wizard in a modern city, soaking in technology, a goldmine for his powers and a source of constant danger if he allowed his powers to run unchecked. Max needed to learn to\n",
            "\n",
            "Generated Script Content:\n",
            "INT. AIRPORT TERMINAL - DAY\n",
            "\n",
            "Two figures, JAMES and SARAH - both in their 40s, full of life, yet marked with the footprints of time - spot each other across the busy terminal.\n",
            "\n",
            "JAMES, a successful entrepreneur, spots SARAH, a renowned surgeon, first. His eyes light up.\n",
            "\n",
            "JAMES:\n",
            "(eyes wide, smiling)\n",
            "Sarah?\n",
            "\n",
            "SARAH turns around after hearing her name, a little surprised.\n",
            "\n",
            "SARAH:\n",
            "(frowning, unsure )\n",
            "James, is that you?\n",
            "\n",
            "They approach each other slowly, the noise of the terminal fading into a silent echo as old memories awaken.\n",
            "\n",
            "JAMES:\n",
            "(smiling warmly)\n",
            "In the flesh. Can't believe it's been 20 years.\n",
            "\n",
            "SARAH:\n",
            "(eased, chuckles)\n",
            "20 years, huh? Feels like a lifetime ago. \n",
            "\n",
            "JAMES:\n",
            "(smiling nostalgically)\n",
            "Remember the times we said we'd conquer the world together?\n",
            "\n",
            "SARAH:\n",
            "(laughs)\n",
            "And look at us, worlds apart yet somehow conquering in our own ways.\n",
            "\n",
            "JAMES:\n",
            "Still the same charming Sarah, aren't you?\n",
            "\n",
            " SARAH blushes slightly, a faint hint of their shared past reflected in her eyes.\n",
            "\n",
            "SARAH:\n",
            "And you're still the same old dreamer, James.\n",
            "\n",
            "They share a moment of silence, reminisce their old days but also acknowledging the years they spent apart.\n",
            "\n",
            "JAMES:\n",
            "(profound)\n",
            "Guess old habits die hard.\n",
            "\n",
            "SARAH:\n",
            "(gradually smiling)\n",
            "I'm happy they didn't, James. \n",
            "\n",
            "Their chortling laughter fills the scene, leaving the onlookers in their own world admiring their bond. Their glance exchanges an unspoken promise of a rekindled friendship that's here to stay.\n",
            "\n",
            "FADE OUT.\n",
            "\n",
            "\n",
            "Generated Music Composition Content:\n",
            "Title: \"Harmonic Resurgence in E Minor\"\n",
            "\n",
            "[[Sheet Music]]\n",
            "\n",
            "[Key of E Minor]\n",
            "\n",
            "[Tempo: Allegro]\n",
            "\n",
            "Right Hand:\n",
            "E | 1/8 Fâ™¯ 1/8 G 1/8 Fâ™¯ 1/8 E 1/4 D 1/8 C 1/8 B 1/8 A \n",
            "G l 1/4 A 1/4 G 1/4 Fâ™¯ 1/4 E 1/16 Fâ™¯ + 1/16 G \n",
            "\n",
            "Left Hand:\n",
            "E |1/4 E 1/4 Fâ™¯ 1/4 G 1/4 B \n",
            "E l 1/4 C 1/4 D 1/4 E 1/4 Fâ™¯ 1/4 G\n",
            "\n",
            "[Tempo: Largo]\n",
            "\n",
            "Right Hand:\n",
            "E | 1/4 A 1/8 B 1/8 C 1/4 D 1/8 E 1/8 Fâ™¯  \n",
            "C l 1/4 D 1/8 E 1/8 Fâ™¯ 1/4 G 1/8 A 1/8 B \n",
            "\n",
            "Left Hand:\n",
            "E | 1/4 B 1/4 C 1/4 D 1/4 E \n",
            "D l 1/4 E 1/4 Fâ™¯ 1/4 G 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Healthcare\n"
      ],
      "metadata": {
        "id": "8ORpnsnf_P60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Setup OpenAI client\n",
        "client = openai.OpenAI(api_key=get_api_key('OPENAI_API_KEY'))\n",
        "\n",
        "def generate_medical_summary(research_text, max_tokens=300):\n",
        "    \"\"\"\n",
        "    Summarize medical research articles using GPT-4.\n",
        "    Parameters:\n",
        "        research_text (str): Text of the medical research article.\n",
        "        max_tokens (int): Maximum number of tokens for the summary.\n",
        "    \"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that summarizes medical research articles.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Summarize this medical research: {research_text}\"}\n",
        "        ],\n",
        "        max_tokens=max_tokens\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "def generate_care_plan(patient_details, max_tokens=300):\n",
        "    \"\"\"\n",
        "    Generate a patient care plan based on medical history and current symptoms using GPT-4.\n",
        "    Parameters:\n",
        "        patient_details (str): Description of the patient's medical history and symptoms.\n",
        "        max_tokens (int): Maximum number of tokens for the care plan.\n",
        "    \"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are an assistant that generates patient care plans based on their medical history and symptoms.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Create a care plan for this patient: {patient_details}\"}\n",
        "        ],\n",
        "        max_tokens=max_tokens\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# Example usage\n",
        "research_text = \"A recent study on the effects of a new diabetes medication shows promising results in reducing blood sugar levels without significant side effects.\"\n",
        "patient_details = \"Patient is a 58-year-old male with a history of Type 2 Diabetes and hypertension. Recent symptoms include increased thirst and frequent urination.\"\n",
        "\n",
        "# Generate medical summary\n",
        "medical_summary = generate_medical_summary(research_text)\n",
        "print(\"Medical Research Summary:\")\n",
        "print(medical_summary)\n",
        "\n",
        "# Generate patient care plan\n",
        "care_plan = generate_care_plan(patient_details)\n",
        "print(\"\\nPatient Care Plan:\")\n",
        "print(care_plan)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsIIWfCe-xQJ",
        "outputId": "d92e4fc4-8d7b-4fda-c54d-27e0f16c42a3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Medical Research Summary:\n",
            "The recent research study focuses on a new diabetes medication that has demonstrated positive outcomes. The results revealed that this new drug is capable of successfully decreasing blood sugar levels. Crucially, it also causes minimal major side effects, indicating it could represent a beneficial new treatment solution for diabetes patients.\n",
            "\n",
            "Patient Care Plan:\n",
            "Patient Information: \n",
            "- 58-year-old male \n",
            "- Past medical history of Type 2 Diabetes and Hypertension \n",
            "- Recent symptoms: increased thirst and frequent urination\n",
            "\n",
            "**Patient Care Plan**\n",
            "\n",
            "1. **Problem identification:** \n",
            "   High blood sugar (hyperglycemia) signs represented by increased thirst and frequent urination indicates uncontrolled diabetes condition. Hypertension (high blood pressure) may complicate things if not properly managed.\n",
            "\n",
            "2. **Goal establishment:**\n",
            "   Primary aims include getting patient's blood sugar levels under control, managing blood pressure, and maintaining a healthy lifestyle to avoid complications related to these conditions.\n",
            "\n",
            "3. **Medical intervention and Monitoring:**\n",
            "   - Continual monitoring of patient's blood sugar levels, blood pressure, and kidney function.\n",
            "   - Regular medication for diabetes and hypertension as per physicianâ€™s recommendation which might include insulin or oral hypoglycemic for diabetes and antihypertensive medication. \n",
            "   - Regular appointments with healthcare professionals for check-ups and adjustments of medication if needed. \n",
            "   - If not done recently, an eye examination should be arranged to monitor for diabetic retinopathy.\n",
            "\n",
            "4. **Diet and Lifestyle adjustments:**\n",
            "   - Recommend consultation with a dietitian to establish a diabetic-friendly, low-sodium diet plan.\n",
            "   - Encourage daily physical activity, starting with low intensity exercises like walking and gradually increase intensity as tolerated.\n",
            "   - Alcohol moderation and smoking cessation if applicable.\n",
            "   - Recommend maintaining a healthy weight.\n",
            "\n",
            "5\n"
          ]
        }
      ]
    }
  ]
}
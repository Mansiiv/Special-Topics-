{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nvG2VCVG0QOJ"
      },
      "outputs": [],
      "source": [
        "# Ensure necessary libraries are installed\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install(package):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "\n",
        "install(\"openai\")\n",
        "install(\"langchain\")\n",
        "\n",
        "# Import necessary libraries\n",
        "import openai\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "import os\n",
        "\n",
        "# Set up OpenAI API key\n",
        "# Replace 'your_openai_api_key_here' with your actual OpenAI API key\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "def get_response(prompt, model=\"gpt-3.5-turbo\", max_tokens=300):\n",
        "    \"\"\"\n",
        "    Helper function to call OpenAI's GPT model.\n",
        "    Args:\n",
        "        prompt (str): The input prompt for the GPT model.\n",
        "        model (str): The GPT model to use.\n",
        "        max_tokens (int): The maximum number of tokens for the response.\n",
        "    Returns:\n",
        "        str: The response from the GPT model.\n",
        "    \"\"\"\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        max_tokens=max_tokens,\n",
        "        temperature=0\n",
        "    )\n",
        "    return response[\"choices\"][0][\"message\"][\"content\"].strip()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai==0.28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7UHkqIV3Yf7",
        "outputId": "41d902c3-7e2b-4e4c-ba3b-73dab98664c5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.11.9)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.8.30)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->openai==0.28) (4.12.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the get_response function\n",
        "def get_response(prompt, model=\"gpt-3.5-turbo\", max_tokens=300):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        max_tokens=max_tokens,\n",
        "        temperature=0\n",
        "    )\n",
        "    return response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
        "\n",
        "# Zero-Shot Prompting Example\n",
        "print(\"### 1. Zero-Shot Prompting\\n\")\n",
        "zero_shot_prompt_success = \"\"\"Answer the following question: What is the largest ocean on Earth?\"\"\"\n",
        "response_success = get_response(zero_shot_prompt_success)\n",
        "print(f\"Success Case:\\nPrompt: {zero_shot_prompt_success}\\nResponse: {response_success}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04BY101W6njD",
        "outputId": "9a617220-99d2-42a2-a675-72251148c521"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### 1. Zero-Shot Prompting\n",
            "\n",
            "Success Case:\n",
            "Prompt: Answer the following question: What is the largest ocean on Earth?\n",
            "Response: The largest ocean on Earth is the Pacific Ocean.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One-Shot Prompting Example\n",
        "print(\"### 2. One-Shot Prompting\\n\")\n",
        "\n",
        "# Success Case\n",
        "one_shot_prompt_success = \"\"\"\n",
        "Translate the following English sentence to French.\n",
        "\n",
        "English: \"Good evening.\"\n",
        "French: \"Bonsoir.\"\n",
        "\n",
        "Now translate this sentence:\n",
        "English: \"How are you?\"\n",
        "French:\n",
        "\"\"\"\n",
        "response_success = get_response(one_shot_prompt_success)\n",
        "print(f\"Success Case:\\nPrompt: {one_shot_prompt_success}\\nResponse: {response_success}\\n\")\n",
        "\n",
        "# Failure Case\n",
        "one_shot_prompt_failure = \"\"\"\n",
        "Translate the following English sentence to German.\n",
        "\n",
        "English: \"I need help.\"\n",
        "German:\n",
        "\"\"\"\n",
        "response_failure = get_response(one_shot_prompt_failure)\n",
        "print(f\"Failure Case:\\nPrompt: {one_shot_prompt_failure}\\nResponse: {response_failure}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8cCr4nh6n4x",
        "outputId": "d5b18047-b2d1-4a12-d0c0-8e76e222d59f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### 2. One-Shot Prompting\n",
            "\n",
            "Success Case:\n",
            "Prompt: \n",
            "Translate the following English sentence to French.\n",
            "\n",
            "English: \"Good evening.\"\n",
            "French: \"Bonsoir.\"\n",
            "\n",
            "Now translate this sentence:\n",
            "English: \"How are you?\"\n",
            "French:\n",
            "\n",
            "Response: \"Comment vas-tu ?\"\n",
            "\n",
            "Failure Case:\n",
            "Prompt: \n",
            "Translate the following English sentence to German.\n",
            "\n",
            "English: \"I need help.\"\n",
            "German:\n",
            "\n",
            "Response: \"Ich brauche Hilfe.\"\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Few-Shot Prompting Example\n",
        "print(\"### 3. Few-Shot Prompting\\n\")\n",
        "\n",
        "# Success Case\n",
        "few_shot_prompt_success = \"\"\"\n",
        "Identify the animal based on its sound.\n",
        "\n",
        "Examples:\n",
        "Sound: \"Meow\" Animal: \"Cat\"\n",
        "Sound: \"Bark\" Animal: \"Dog\"\n",
        "\n",
        "Now:\n",
        "Sound: \"Roar\" Animal:\n",
        "\"\"\"\n",
        "response_success = get_response(few_shot_prompt_success)\n",
        "print(f\"Success Case:\\nPrompt: {few_shot_prompt_success}\\nResponse: {response_success}\\n\")\n",
        "\n",
        "# Failure Case\n",
        "few_shot_prompt_failure = \"\"\"\n",
        "Identify the animal based on its sound.\n",
        "\n",
        "Examples:\n",
        "Sound: \"Quack\" Animal: \"Duck\"\n",
        "Sound: \"Moo\" Animal: \"Cow\"\n",
        "\n",
        "Now:\n",
        "Sound: \"Hiss\" Animal:\n",
        "\"\"\"\n",
        "response_failure = get_response(few_shot_prompt_failure)\n",
        "print(f\"Failure Case:\\nPrompt: {few_shot_prompt_failure}\\nResponse: {response_failure}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNQYBGaI7M5b",
        "outputId": "ddb02a29-bf74-432a-c0d1-5570f00ad780"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### 3. Few-Shot Prompting\n",
            "\n",
            "Success Case:\n",
            "Prompt: \n",
            "Identify the animal based on its sound.\n",
            "\n",
            "Examples:\n",
            "Sound: \"Meow\" Animal: \"Cat\"\n",
            "Sound: \"Bark\" Animal: \"Dog\"\n",
            "\n",
            "Now:\n",
            "Sound: \"Roar\" Animal:\n",
            "\n",
            "Response: Lion\n",
            "\n",
            "Failure Case:\n",
            "Prompt: \n",
            "Identify the animal based on its sound.\n",
            "\n",
            "Examples:\n",
            "Sound: \"Quack\" Animal: \"Duck\"\n",
            "Sound: \"Moo\" Animal: \"Cow\"\n",
            "\n",
            "Now:\n",
            "Sound: \"Hiss\" Animal:\n",
            "\n",
            "Response: Snake\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chain-of-Thought Prompting Example\n",
        "print(\"### 4. Chain-of-Thought Prompting\\n\")\n",
        "\n",
        "# Success Case\n",
        "chain_of_thought_success = \"\"\"Solve the math problem step-by-step:\n",
        "If a train travels at 80 mph for 3 hours, how far does it travel?\n",
        "\n",
        "Solution:\n",
        "\"\"\"\n",
        "response_success = get_response(chain_of_thought_success)\n",
        "print(f\"Success Case:\\nPrompt: {chain_of_thought_success}\\nResponse: {response_success}\\n\")\n",
        "\n",
        "# Failure Case\n",
        "chain_of_thought_failure = \"\"\"Solve the math problem step-by-step:\n",
        "If a car travels at 70 mph for 2.5 hours, how far does it travel?\n",
        "\n",
        "Solution:\n",
        "\"\"\"\n",
        "response_failure = get_response(chain_of_thought_failure)\n",
        "print(f\"Failure Case:\\nPrompt: {chain_of_thought_failure}\\nResponse: {response_failure}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSpYuiT37Z1a",
        "outputId": "38089dff-71be-47b2-f788-97f26a0f5c69"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### 4. Chain-of-Thought Prompting\n",
            "\n",
            "Success Case:\n",
            "Prompt: Solve the math problem step-by-step:\n",
            "If a train travels at 80 mph for 3 hours, how far does it travel?\n",
            "\n",
            "Solution:\n",
            "\n",
            "Response: To find the distance traveled by the train, we can use the formula:\n",
            "\n",
            "Distance = Speed x Time\n",
            "\n",
            "Given that the speed of the train is 80 mph and it travels for 3 hours, we can plug in these values into the formula:\n",
            "\n",
            "Distance = 80 mph x 3 hours\n",
            "Distance = 240 miles\n",
            "\n",
            "Therefore, the train travels a distance of 240 miles.\n",
            "\n",
            "Failure Case:\n",
            "Prompt: Solve the math problem step-by-step:\n",
            "If a car travels at 70 mph for 2.5 hours, how far does it travel?\n",
            "\n",
            "Solution:\n",
            "\n",
            "Response: To find the distance traveled, we can use the formula:\n",
            "\n",
            "Distance = Speed x Time\n",
            "\n",
            "Given that the car travels at 70 mph for 2.5 hours, we can plug in the values:\n",
            "\n",
            "Distance = 70 mph x 2.5 hours\n",
            "Distance = 175 miles\n",
            "\n",
            "Therefore, the car travels 175 miles.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instruction Following Example\n",
        "print(\"### 5. Instruction Following\\n\")\n",
        "\n",
        "# Success Case\n",
        "instruction_following_success = \"\"\"Please summarize the following text in one sentence:\n",
        "Text: \"Artificial intelligence aims to create machines that can perform tasks requiring human intelligence, such as decision-making and language understanding.\"\n",
        "\n",
        "Summary:\n",
        "\"\"\"\n",
        "response_success = get_response(instruction_following_success)\n",
        "print(f\"Success Case:\\nPrompt: {instruction_following_success}\\nResponse: {response_success}\\n\")\n",
        "\n",
        "# Failure Case\n",
        "instruction_following_failure = \"\"\"Please summarize the following text in one sentence:\n",
        "Text: \"Machine learning, a subset of AI, focuses on building systems that can learn from data.\"\n",
        "\n",
        "Summary:\n",
        "\"\"\"\n",
        "response_failure = get_response(instruction_following_failure)\n",
        "print(f\"Failure Case:\\nPrompt: {instruction_following_failure}\\nResponse: {response_failure}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ref0m0Lg7cPu",
        "outputId": "8da1c34c-b989-40a4-81e0-6597893d953d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### 5. Instruction Following\n",
            "\n",
            "Success Case:\n",
            "Prompt: Please summarize the following text in one sentence:\n",
            "Text: \"Artificial intelligence aims to create machines that can perform tasks requiring human intelligence, such as decision-making and language understanding.\"\n",
            "\n",
            "Summary:\n",
            "\n",
            "Response: Artificial intelligence seeks to develop machines capable of tasks that typically require human intelligence, like decision-making and language comprehension.\n",
            "\n",
            "Failure Case:\n",
            "Prompt: Please summarize the following text in one sentence:\n",
            "Text: \"Machine learning, a subset of AI, focuses on building systems that can learn from data.\"\n",
            "\n",
            "Summary:\n",
            "\n",
            "Response: Machine learning is a subset of AI that involves building systems capable of learning from data.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Roleplaying Example\n",
        "print(\"### 6. Roleplaying\\n\")\n",
        "\n",
        "# Success Case\n",
        "roleplaying_success = \"\"\"You are a fitness coach. Provide advice on improving flexibility.\n",
        "\"\"\"\n",
        "response_success = get_response(roleplaying_success)\n",
        "print(f\"Success Case:\\nPrompt: {roleplaying_success}\\nResponse: {response_success}\\n\")\n",
        "\n",
        "# Failure Case\n",
        "roleplaying_failure = \"\"\"You are a chef. Provide a recipe for a healthy salad.\n",
        "\"\"\"\n",
        "response_failure = get_response(roleplaying_failure)\n",
        "print(f\"Failure Case:\\nPrompt: {roleplaying_failure}\\nResponse: {response_failure}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfWFRCWA7eN_",
        "outputId": "44ee604b-8e9a-4067-82f2-ef3151a688cd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### 6. Roleplaying\n",
            "\n",
            "Success Case:\n",
            "Prompt: You are a fitness coach. Provide advice on improving flexibility.\n",
            "\n",
            "Response: Improving flexibility is an important aspect of overall fitness and can help prevent injuries, improve performance, and enhance overall well-being. Here are some tips to help improve flexibility:\n",
            "\n",
            "1. Incorporate stretching into your daily routine: Make sure to stretch before and after your workouts to help improve flexibility and prevent muscle tightness.\n",
            "\n",
            "2. Focus on major muscle groups: Pay special attention to stretching your hamstrings, quadriceps, calves, hips, and shoulders, as these areas tend to be tight for many people.\n",
            "\n",
            "3. Hold stretches for at least 30 seconds: To effectively improve flexibility, hold each stretch for at least 30 seconds to allow your muscles to relax and lengthen.\n",
            "\n",
            "4. Practice yoga or Pilates: Both yoga and Pilates are great ways to improve flexibility, as they focus on stretching and strengthening the muscles through a series of poses and exercises.\n",
            "\n",
            "5. Use a foam roller: Foam rolling can help release tight muscles and improve flexibility by breaking up knots and adhesions in the muscles.\n",
            "\n",
            "6. Stay hydrated: Drinking plenty of water can help keep your muscles hydrated and supple, which can improve flexibility.\n",
            "\n",
            "7. Listen to your body: It's important to listen to your body and not push yourself too hard when stretching. Stretch to the point of mild discomfort, but never to the point of pain.\n",
            "\n",
            "By incorporating these tips into your fitness routine, you can improve your flexibility and enhance your overall fitness level. Remember to be consistent and patient, as flexibility improvements take time and\n",
            "\n",
            "Failure Case:\n",
            "Prompt: You are a chef. Provide a recipe for a healthy salad.\n",
            "\n",
            "Response: Quinoa and Kale Salad with Lemon Vinaigrette\n",
            "\n",
            "Ingredients:\n",
            "- 1 cup quinoa\n",
            "- 2 cups water\n",
            "- 1 bunch kale, stems removed and chopped\n",
            "- 1 bell pepper, diced\n",
            "- 1 cucumber, diced\n",
            "- 1/2 red onion, thinly sliced\n",
            "- 1/4 cup chopped fresh parsley\n",
            "- 1/4 cup chopped fresh mint\n",
            "- 1/4 cup crumbled feta cheese\n",
            "- 1/4 cup toasted pine nuts\n",
            "\n",
            "For the Lemon Vinaigrette:\n",
            "- 1/4 cup olive oil\n",
            "- 2 tablespoons fresh lemon juice\n",
            "- 1 teaspoon Dijon mustard\n",
            "- 1 clove garlic, minced\n",
            "- Salt and pepper to taste\n",
            "\n",
            "Instructions:\n",
            "1. Rinse the quinoa under cold water. In a medium saucepan, bring the water to a boil. Add the quinoa, reduce heat to low, cover, and simmer for 15 minutes. Remove from heat and let sit for 5 minutes. Fluff with a fork and let cool.\n",
            "2. In a large bowl, combine the cooked quinoa, kale, bell pepper, cucumber, red onion, parsley, and mint.\n",
            "3. In a small bowl, whisk together the olive oil, lemon juice, Dijon mustard, garlic, salt, and pepper to make the vinaigrette.\n",
            "4. Pour the vinaigrette over the salad and toss to combine.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Augmentation Example\n",
        "print(\"### 7. Data Augmentation\\n\")\n",
        "\n",
        "# Success Case\n",
        "data_augmentation_success = \"\"\"Generate synonyms for the word \"happy\".\n",
        "\"\"\"\n",
        "response_success = get_response(data_augmentation_success)\n",
        "print(f\"Success Case:\\nPrompt: {data_augmentation_success}\\nResponse: {response_success}\\n\")\n",
        "\n",
        "# Failure Case\n",
        "data_augmentation_failure = \"\"\"Generate synonyms for the word \"angry\".\n",
        "\"\"\"\n",
        "response_failure = get_response(data_augmentation_failure)\n",
        "print(f\"Failure Case:\\nPrompt: {data_augmentation_failure}\\nResponse: {response_failure}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inMtRmbH7gDM",
        "outputId": "003ced25-af65-44dc-f8fa-f95b639dc0c8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### 7. Data Augmentation\n",
            "\n",
            "Success Case:\n",
            "Prompt: Generate synonyms for the word \"happy\".\n",
            "\n",
            "Response: joyful, content, delighted, pleased, cheerful, ecstatic, elated, jubilant, satisfied, blissful\n",
            "\n",
            "Failure Case:\n",
            "Prompt: Generate synonyms for the word \"angry\".\n",
            "\n",
            "Response: 1. Furious\n",
            "2. Irritated\n",
            "3. Mad\n",
            "4. Upset\n",
            "5. Enraged\n",
            "6. Fuming\n",
            "7. Wrathful\n",
            "8. Incensed\n",
            "9. Raging\n",
            "10. Livid\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Style Transfer Example\n",
        "print(\"### 8. Style Transfer\\n\")\n",
        "\n",
        "# Success Case\n",
        "style_transfer_success = \"\"\"Rewrite the following sentence in a formal tone:\n",
        "\"I need this done ASAP.\"\n",
        "\"\"\"\n",
        "response_success = get_response(style_transfer_success)\n",
        "print(f\"Success Case:\\nPrompt: {style_transfer_success}\\nResponse: {response_success}\\n\")\n",
        "\n",
        "# Failure Case\n",
        "style_transfer_failure = \"\"\"Rewrite the following sentence in a casual tone:\n",
        "\"I respectfully request your assistance with this matter.\"\n",
        "\"\"\"\n",
        "response_failure = get_response(style_transfer_failure)\n",
        "print(f\"Failure Case:\\nPrompt: {style_transfer_failure}\\nResponse: {response_failure}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blDgPENv7zqA",
        "outputId": "c4428e23-7b28-42dd-e3d9-7a50b9a279c9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### 8. Style Transfer\n",
            "\n",
            "Success Case:\n",
            "Prompt: Rewrite the following sentence in a formal tone:\n",
            "\"I need this done ASAP.\"\n",
            "\n",
            "Response: I require this to be completed as soon as possible.\n",
            "\n",
            "Failure Case:\n",
            "Prompt: Rewrite the following sentence in a casual tone:\n",
            "\"I respectfully request your assistance with this matter.\"\n",
            "\n",
            "Response: \"Hey, can you help me out with this?\"\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Delimiters to Specify Context Example\n",
        "print(\"### 9. Using Delimiters to Specify Context\\n\")\n",
        "\n",
        "# Success Case\n",
        "delimiter_success = \"\"\"Extract the names of all people mentioned in the following text, delimited by triple dashes:\n",
        "---\n",
        "Alice and Bob went to the market where they met Charlie.\n",
        "---\n",
        "Names:\n",
        "\"\"\"\n",
        "response_success = get_response(delimiter_success)\n",
        "print(f\"Success Case:\\nPrompt: {delimiter_success}\\nResponse: {response_success}\\n\")\n",
        "\n",
        "# Failure Case\n",
        "delimiter_failure = \"\"\"Extract the names of all people mentioned in the following text, delimited by triple dashes:\n",
        "---\n",
        "Tom and Jerry visited the Grand Canyon.\n",
        "---\n",
        "Names:\n",
        "\"\"\"\n",
        "response_failure = get_response(delimiter_failure)\n",
        "print(f\"Failure Case:\\nPrompt: {delimiter_failure}\\nResponse: {response_failure}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPsKZwIn71VB",
        "outputId": "3acdc169-f078-44a8-b8fd-26d76a01b7cb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### 9. Using Delimiters to Specify Context\n",
            "\n",
            "Success Case:\n",
            "Prompt: Extract the names of all people mentioned in the following text, delimited by triple dashes:\n",
            "---\n",
            "Alice and Bob went to the market where they met Charlie.\n",
            "---\n",
            "Names:\n",
            "\n",
            "Response: Alice\n",
            "Bob\n",
            "Charlie\n",
            "\n",
            "Failure Case:\n",
            "Prompt: Extract the names of all people mentioned in the following text, delimited by triple dashes:\n",
            "---\n",
            "Tom and Jerry visited the Grand Canyon.\n",
            "---\n",
            "Names:\n",
            "\n",
            "Response: Tom\n",
            "Jerry\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wY727lsX721l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}